{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can download the pretrained weights from the following link \n",
    "#https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "#or you can find the detailed documentation https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "\n",
    "from keras.models import model_from_json\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    #img = load_img(image_path, target_size=(224, 224))\n",
    "    #img = img_to_array(img)\n",
    "    #img = np.expand_dims(image_path, axis=0)\n",
    "    img = preprocess_input(image_path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.08292549848556519\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.04371178150177002\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.19212859869003296\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.08876395225524902\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.052476704120635986\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.18071526288986206\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.08551609516143799\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.05181467533111572\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.20288580656051636\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.10538369417190552\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.07235085964202881\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.13891267776489258\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.10935831069946289\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.07885009050369263\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.15610480308532715\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.10007888078689575\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.06393283605575562\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.1755242943763733\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.09998410940170288\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.08206331729888916\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.2062585949897766\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.03693467378616333\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.17500633001327515\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.08865034580230713\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.061350345611572266\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.22721213102340698\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.050932884216308594\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.21959763765335083\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.051038503646850586\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.19203925132751465\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.07196176052093506\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.17199081182479858\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.09010076522827148\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.05901622772216797\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.09531766176223755\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.0829077959060669\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.054867684841156006\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.1386944055557251\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n",
      "0.09931665658950806\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.07838785648345947\n",
      "dataset/face.1.jpg\n",
      "-----------------------------\n",
      "0.22842401266098022\n",
      "dataset/0004_01.jpg\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "from time import localtime, strftime\n",
    "import os\n",
    "import time\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('Cascades/haarcascade_frontalface_default.xml')\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "video_capture.set(3, 640) # set video width \n",
    "video_capture.set(4, 480) # set video height \n",
    "threshold=0.2\n",
    "(width, height) = (224, 224)\n",
    "idx=0\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 800,600)\n",
    "\n",
    "\n",
    "a=[]\n",
    "ph=[]\n",
    "b={}\n",
    "images=glob.glob('dataset/*.jpg')\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i])\n",
    "    face_resize = cv2.resize(image, (224, 224))\n",
    "    face_resize = face_resize.reshape(1,224,224,3)\n",
    "    img1_representation = vgg_face_descriptor.predict(preprocess_image(face_resize))[0,:]\n",
    "    b = {i:img1_representation}\n",
    "    a.append(b)\n",
    "    ph.append(os.path.basename(images[i]))\n",
    "print(len(a))\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    processing_start_time = time.time()\n",
    "    time_counter = 0\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        frame,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        #images=glob.glob('dataset/*.jpg')\n",
    "        rrec = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        face = frame[y:y + h, x:x + w] \n",
    "        face_resize = cv2.resize(face, (width, height))\n",
    "        face_resize = face_resize.reshape(1,224,224,3)\n",
    "        img1_representation = vgg_face_descriptor.predict(preprocess_image(face_resize))[0,:]\n",
    "        \n",
    "        cosines=[]\n",
    "        for i in range(len(a)):\n",
    "            cosine_similarity = findCosineSimilarity(img1_representation, a[i][i])\n",
    "            cosines.append(cosine_similarity)\n",
    "        \n",
    "        minimum = cosines.index(min(cosines))\n",
    "        #percent = (0.4-float(cosines[minimum]))*100/0.4\n",
    "        #print(str(percent)+'%')\n",
    "        print(cosines[minimum])\n",
    "        print(images[minimum])\n",
    "        print('-----------------------------')\n",
    "        \n",
    "        if float(cosines[minimum])<0.22:\n",
    "            text=str(ph[minimum])\n",
    "            \n",
    "        if float(cosines[minimum])>0.25:\n",
    "            text='not found'\n",
    "            idx=len(a)\n",
    "            #face_name = input('\\n enter Directory name end press ==> ')\n",
    "            write_name = 'dataset/face.'+str(idx)+'.jpg'\n",
    "            base_name = 'face.'+str(idx)+'.jpg'\n",
    "            cv2.imwrite(write_name, face)\n",
    "            images.append(write_name)\n",
    "            ph.append(base_name)\n",
    "            b={idx:img1_representation}\n",
    "            a.append(b)\n",
    "            print('Person added')\n",
    "            print('---------------------')\n",
    "        \n",
    "        cv2.putText(rrec,text,(x,y), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),1,cv2.LINE_AA)        \n",
    "        \n",
    "    cv2.imshow('image', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
